{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/EdSgHmMTqJvC0cevwjjK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u5HW5dae5yy"
      },
      "outputs": [],
      "source": [
        "import itertools, os\n",
        "import numpy as np\n",
        "import spacy\n",
        "import torch\n",
        "from torchtext import data, datasets\n",
        "from torchtext.vocab import Vectors, GloVe\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "def preprocess(vocab_size, batchsize, max_sent_len=20):\n",
        "    de_spacy = spacy.load('de')\n",
        "    en_spacy = spacy.load('en')\n",
        "\n",
        "    def tokenize(text, lang='en'):\n",
        "        if lang is 'de':\n",
        "            return [tok.text for tok in de_spacy.tokenizer(text)]\n",
        "        elif lang is 'en':\n",
        "            return [tok.text for tok in en_spacy.tokenizer(text)]\n",
        "\n",
        "    BOS_WORD = '<s>'\n",
        "    EOS_WORD = '</s>'\n",
        "    DE = data.Field(tokenize=lambda x: tokenize(x, 'de'))\n",
        "    EN = data.Field(tokenize=tokenize, init_token=BOS_WORD, eos_token=EOS_WORD)\n",
        "\n",
        "    train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN), filter_pred = lambda x: max(len(vars(x)['src']), len(vars(x)['trg'])) <= max_sent_len)\n",
        "\n",
        "\n",
        "    if vocab_size > 0:\n",
        "        DE.build_vocab(train.src, min_freq=5, max_size=vocab_size)\n",
        "        EN.build_vocab(train.trg, min_freq=5, max_size=vocab_size)\n",
        "    else:\n",
        "        DE.build_vocab(train.src, min_freq=5)\n",
        "        EN.build_vocab(train.trg, min_freq=5)\n",
        "\n",
        "    train_iter = data.BucketIterator(train, batch_size=batchsize, device=-1, repeat=False, sort_key=lambda x: len(x.src))\n",
        "    val_iter = data.BucketIterator(val, batch_size=1, device=-1, repeat=False, sort_key=lambda x: len(x.src))\n",
        "    \n",
        "    return DE, EN, train_iter, val_iter\n",
        "\n",
        "def load_embeddings(SRC, TRG, np_src_file, np_trg_file):\n",
        "    if os.path.isfile(np_src_file) and os.path.isfile(np_trg_file):\n",
        "        emb_tr_src = torch.from_numpy(np.load(np_src_file))\n",
        "        emb_tr_trg = torch.from_numpy(np.load(np_trg_file))\n",
        "    else: \n",
        "        raise Exception('Vectors are unloadable')\n",
        "    return emb_tr_src, emb_tr_trg\n",
        "    "
      ]
    }
  ]
}